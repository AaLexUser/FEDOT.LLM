{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T13:22:19.787039Z",
     "start_time": "2024-09-18T13:22:15.041334Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "from pathlib import Path\n",
    "module_path = os.path.abspath(os.path.join(os.sep.join(['..'])))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from fedot_llm.data.loaders import PathDatasetLoader\n",
    "from fedot_llm.main import FedotAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T13:22:21.231913Z",
     "start_time": "2024-09-18T13:22:21.226681Z"
    }
   },
   "outputs": [],
   "source": [
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        print(f\"No {var} in env\")\n",
    "\n",
    "load_dotenv()\n",
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "_set_env(\"OPENAI_TOKEN\")\n",
    "_set_env(\"VSEGPT_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T13:22:21.920748Z",
     "start_time": "2024-09-18T13:22:21.917586Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"FEDOT.LLM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T13:22:23.177687Z",
     "start_time": "2024-09-18T13:22:22.960837Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-4o-mini', base_url='https://models.inference.ai.azure.com', api_key=os.environ['OPENAI_TOKEN'])\n",
    "# llm = ChatOpenAI(model='gpt-4o', base_url='https://models.inference.ai.azure.com', api_key=os.environ['OPENAI_TOKEN'])\n",
    "# llm = ChatOpenAI(model='openai/gpt-4o-mini', base_url='https://api.vsegpt.ru/v1/', api_key=os.environ['VSEGPT_TOKEN'])\n",
    "# llm = ChatOpenAI(model='meta-llama/llama-3.1-70b-instruct', base_url='https://api.vsegpt.ru/v1/', api_key=os.environ['VSEGPT_TOKEN'])\n",
    "\n",
    "msg=\"\"\"Create a model that perform this task:\n",
    "Our client is an insurance company that has provided health insurance to its customers.\n",
    "They are interested in whether the policyholders (customers) from last year\n",
    "will also be interested in the car insurance provided by the company.\"\"\"\n",
    "\n",
    "dataset_path = Path(module_path) / 'datasets' / 'Health_Insurance'\n",
    "dataset = PathDatasetLoader.load(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "================== HumanMessage ==================\n",
       "\n",
       "Fedot automl classification example?\n",
       "\n",
       "=================== Supervisor ===================\n",
       "\n",
       "calls:\n",
       "  ResearcherAgent:\n",
       "    args:\n",
       "      question: Fedot AutoML classification example\n",
       "\n",
       "\n",
       "================ ResearcherAgent =================\n",
       "\n",
       "To perform a classification task using FEDOT AutoML, you can follow these steps:\n",
       "\n",
       "1. **Import the FEDOT API**:\n",
       "   ```python\n",
       "   from fedot.api.main import Fedot\n",
       "   ```\n",
       "\n",
       "2. **Load your data**:\n",
       "   Load your training and test data from CSV files into Pandas dataframes:\n",
       "   ```python\n",
       "   train = pd.DataFrame('train.csv')\n",
       "   test = pd.DataFrame('test.csv')\n",
       "   ```\n",
       "\n",
       "3. **Initialize the FEDOT model**:\n",
       "   Define the type of problem as `classification` and specify the evaluation metric, for example, `roc_auc`:\n",
       "   ```python\n",
       "   model = Fedot(problem='classification', metric='roc_auc')\n",
       "   ```\n",
       "\n",
       "4. **Fit the model**:\n",
       "   Begin the optimization process and obtain the resulting composite pipeline:\n",
       "   ```python\n",
       "   best_pipeline = model.fit(features=train, target='target')\n",
       "   ```\n",
       "\n",
       "5. **Inspect the pipeline**:\n",
       "   After fitting, you can examine the structure of the resulting pipeline:\n",
       "   ```python\n",
       "   best_pipeline.print_structure()\n",
       "   ```\n",
       "\n",
       "This process automates the design of a machine learning pipeline for classification tasks using FEDOT [\\[1\\]](https://fedot.readthedocs.io/en/latest/basics/tabular_data.html)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-19 17:50:35,092 - HTTP Request: POST https://models.inference.ai.azure.com/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from fedot_llm.output.jupyter import JupyterOutput\n",
    "fedot_ai = FedotAI(dataset=dataset, \n",
    "                   model=llm,\n",
    "                   handlers=JupyterOutput().subscribe)\n",
    "async for _ in fedot_ai.ask(\"Fedot automl classification example?\"):\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "================== HumanMessage ==================\n",
       "\n",
       "Create a model that perform this task:\n",
       "Our client is an insurance company that has provided health insurance to its customers.\n",
       "They are interested in whether the policyholders (customers) from last year\n",
       "will also be interested in the car insurance provided by the company.\n",
       "\n",
       "=================== Supervisor ===================\n",
       "\n",
       "calls:\n",
       "  AutoMLAgent:\n",
       "    args:\n",
       "      dataset_description: The dataset consists of policyholder information from an\n",
       "        insurance company, including features such as age, gender, previous health\n",
       "        insurance policies, claim history, customer satisfaction ratings, and whether\n",
       "        they expressed interest in car insurance. The task is to predict if these\n",
       "        policyholders will be interested in purchasing car insurance based on their\n",
       "        profiles.\n",
       "\n",
       "\n",
       "================== AutoMLAgent ===================\n",
       "\n",
       "Here is the pipeline of the model I built:\n",
       "\n",
       "# Model Pipeline\n",
       "The pipeline consists of two stages:\n",
       "1. **Scaling**: This stage prepares the data by standardizing or normalizing it, ensuring that all features contribute equally to the model's performance.\n",
       "2. **Random Forest (RF)**: The model is a Random Forest classifier configured to use 12 jobs for parallel processing, enhancing computational efficiency.\n",
       "\n",
       "# Model Metrics:\n",
       "| Metric   | Value  |\n",
       "|----------|--------|\n",
       "| ROC AUC  | 0.844  |\n",
       "| Accuracy | 0.871  |\n",
       "\n",
       "These metrics indicate that the model performs well. The **ROC AUC** score of 0.844 suggests a strong ability to distinguish between positive and negative classes, where a score of 1 indicates perfect classification. The **accuracy** of 0.871 indicates that 87.1% of the predictions made by the model are correct, reflecting a high level of overall correctness in the predictions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fedot_llm.output.jupyter import JupyterOutput\n",
    "fedot_ai = FedotAI(dataset=dataset, \n",
    "                   model=llm,\n",
    "                   handlers=JupyterOutput().subscribe)\n",
    "async for _ in fedot_ai.ask(msg):\n",
    "    continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
